#!/usr/bin/env python
"""Process load testing log and print time difference of transaction submission time to horizon and commit time to ledger, and horizon response time."""
import csv
import json
import logging
import sys

import strict_rfc3339


logging.basicConfig(level=logging.DEBUG)


def tx_ledger_time(txs, log_path):
    """Process load testing log and print time difference of transaction submission time to horizon and commit time to ledger, and horizon response time."""
    logging.debug('reading logs ...')

    tx_time_diffs = {}
    with open(log_path, 'r') as f:
        for i, raw_line in enumerate(f):
            if i % 100 == 0:
                logging.debug('processing line %d', i)

            json_line = json.loads(raw_line)

            # ignore lines missing tx hash (events we're not interested in)
            tx_hash = json_line.get('tx_hash')
            if not tx_hash:
                continue

            # get transaction hash from all submitted transactions
            if json_line.get('msg') == 'submitting transaction':
                # process only the first result of every transaction submit attempt, ignore retries
                if tx_hash not in tx_time_diffs:
                    tx_time_diffs[tx_hash] = {
                        'horizon_submit_timestamp': strict_rfc3339.rfc3339_to_timestamp(json_line['timestamp']),
                        # commit to ledger timestamp
                        'commit_to_ledger_timestamp': strict_rfc3339.rfc3339_to_timestamp(txs[tx_hash]['created_at'])
                    }
            elif json_line.get('transaction_status'):
                # process only the first result of every transaction submit attempt, ignore retries
                tx = tx_time_diffs[tx_hash]
                if 'status' not in tx:
                    tx.update({
                        'horizon_response_timestamp': strict_rfc3339.rfc3339_to_timestamp(json_line['timestamp']),
                        'status': json_line['transaction_status'],
                    })

    w = csv.DictWriter(sys.stdout, fieldnames=['tx_hash'] + list(list(tx_time_diffs.values())[0].keys()))
    w.writeheader()
    for tx_hash, tx in tx_time_diffs.items():
        w.writerow({'tx_hash': tx_hash, **tx})


def get_ledger_txs(path):
    """Load and return {tx_hash: tx_info} dictionary from file, generated by reports/index_txs.py ."""
    logging.debug('reading transaction dictionary from %s ...', sys.argv[1])

    with open(path, 'r') as f:
        return json.loads(f.read())


if __name__ == '__main__':
    TXS = get_ledger_txs(sys.argv[1])
    tx_ledger_time(TXS, sys.argv[2])
